Importing the dependecies

import numpy as np  # numpy is used for creating numpy array 
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score # this is used to find accuracy of our model

Data Collection and Data Processing

# Loading the data set into pandas data frame
sonar_data = pd.read_csv('/content/Copy of sonar data.csv', header=None) # No header file means no name of the coloumn
# this loads our data into pandas data frame.
#loaded the data frame into varible called sonar data. 


sonar_data.head()  #display first five rows of our data set

# number of rows and coloumn
sonar_data.shape   # 208 instances

sonar_data.describe() #describe ->>> statistical measurement of the data and this give mean standard deviation
# 25% mean 25% of values are less then 0.013350 first coloumn
# it gives better understanding of data.
# for some use cases it is really helpfull

sonar_data[60].value_counts()   # lets find out how many example for rock and mine, 60 is column index, Rock and index is specified in 60 coloumn

sonar_data.groupby(60).mean()  # group the data based on the mine and rock, the difference is really important to predict the object is mine or rock.

# seprating data and Labels
# if I droping coloumn then we specified axis=1 and when row axis=0;
X=sonar_data.drop(columns=60,axis=1)  #storing all the value except the last columns, droping 60 column which is label.
Y=sonar_data[60]  # And storing the 60th columns in Y.

print(X)
print(Y)

Spiliting this data into training and test data

X_train,X_test,Y_train,Y_test=train_test_split(X,Y, test_size=0.1,stratify=Y,random_state=1)
# Y_train is the label of X_train
# Y_test is the label of Y_test
# test_size=0.1 measn 10% of the data we need for testing
# stratify=Y means we split the data based on mine and rock, equal number of rock and mine in training data.
# random_state -> mean split the data in particular order if random_state=1 mean it split the data same way as my data is splited.

print(X.shape,X_train.shape,X_test.shape)  # 21 instance in test data and 187 instance in training data

print(X_train)
print(Y_train)

Model Training ->> Logistic Regression

# Now we train our machine learning model with training data
model = LogisticRegression()  # this load logictics function into varible called model

#training the Logistic Regression Model with training data
model.fit(X_train,Y_train)

Model Evaluation

#accuracy of training data
#accuracy of training data is always more than accuracy on test data because model has already seen the data
# if it is greater then 70% then it is good but is also depend on the amount of data.
# if we use many data point we get good accuracy score.
X_train_prediction=model.predict(X_train)
training_data_accuracy=accuracy_score(X_train_prediction,Y_train)

print('Accuracy on training data: ',training_data_accuracy)

# accuracy on test data, model has never seen this data
X_test_prediction=model.predict(X_test)
test_data_accuracy=accuracy_score(X_test_prediction,Y_test)



print('Accuracy on test data: ',test_data_accuracy)  # outof 100% it will predict 76% correct object wheather it is rock and mine

Making a predictive system

input_data=(0.0286,0.0453,0.0277,0.0174,0.0384,0.099,0.1201,0.1833,0.2105,0.3039,0.2988,0.425,0.6343,0.8198,1,0.9988,0.9508,0.9025,0.7234,0.5122,0.2074,0.3985,0.589,0.2872,0.2043,0.5782,0.5389,0.375,0.3411,0.5067,0.558,0.4778,0.3299,0.2198,0.1407,0.2856,0.3807,0.4158,0.4054,0.3296,0.2707,0.265,0.0723,0.1238,0.1192,0.1089,0.0623,0.0494,0.0264,0.0081,0.0104,0.0045,0.0014,0.0038,0.0013,0.0089,0.0057,0.0027,0.0051,0.0062)
# Changing the input array as numpy array because the processing of numpy array is faster and easy basically changing data point/list to a numoy array
input_data_as_numpy_array=np.asarray(input_data)
# reshape the np array as we are predicting for one instance otherwise our model get confused by the number of data points. (1,-1) represent that there is one instance and we are going to predict the label of this one instance 

input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)

prediction=model.predict(input_data_reshaped)  # model.predict function is going to predict our model as we store our train logistic model into variable called model

print(prediction)
if(prediction[0]=='R'):                          # if it is not in the list then we are not represent with index[0]
  print('The Object is Rock')
else:
  print('The object is Mine')  

